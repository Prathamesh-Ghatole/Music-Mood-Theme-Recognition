{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import httpx\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Process Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINTE PATHS\n",
    "LYRICS_DIR = \"../processed_data/lyrics\"\n",
    "ANNOTATIONS_PATH = \"../processed_data/CLEANED_cal500_annotations.csv\"\n",
    "MODEL_PATH_MISTRAL = \"../models/mistral-7b-instruct-v0.2.Q3_K_M.gguf\"\n",
    "MODEL_PATH_LLAMA =  \"../models/llama-2-7b-chat.Q4_0.gguf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to read lyrics from a folder\n",
    "def read_files_in_folder(folder_path):\n",
    "    file_contents = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            with open(file_path, \"r\") as file:\n",
    "                content = file.read()\n",
    "                file_contents.append(content)\n",
    "    return pd.Series(file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_to_use = [\n",
    "    \"Emotion-Angry_/_Agressive\",\n",
    "    \"Emotion-Arousing_/_Awakening\",\n",
    "    \"Emotion-Bizarre_/_Weird\",\n",
    "    \"Emotion-Calming_/_Soothing\",\n",
    "    \"Emotion-Carefree_/_Lighthearted\",\n",
    "    \"Emotion-Cheerful_/_Festive\",\n",
    "    \"Emotion-Emotional_/_Passionate\",\n",
    "    \"Emotion-Exciting_/_Thrilling\",\n",
    "    \"Emotion-Happy\",\n",
    "    \"Emotion-Laid-back_/_Mellow\",\n",
    "    \"Emotion-Light_/_Playful\",\n",
    "    \"Emotion-Loving_/_Romantic\",\n",
    "    \"Emotion-Pleasant_/_Comfortable\",\n",
    "    \"Emotion-Positive_/_Optimistic\",\n",
    "    \"Emotion-Powerful_/_Strong\",\n",
    "    \"Emotion-Sad\",\n",
    "    \"Emotion-Tender_/_Soft\",\n",
    "    \"Emotion-Touching_/_Loving\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = read_files_in_folder(LYRICS_DIR)\n",
    "annotations = pd.read_csv(ANNOTATIONS_PATH)\n",
    "annotations = annotations[annotations_to_use]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:   no\n",
      "ggml_cuda_init: CUDA_USE_TENSOR_CORES: yes\n",
      "ggml_cuda_init: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA GeForce RTX 3050 Laptop GPU, compute capability 8.6, VMM: yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.95 s, sys: 825 ms, total: 5.78 s\n",
      "Wall time: 22.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "default_model = Llama(\n",
    "    model_path=MODEL_PATH_MISTRAL,\n",
    "    device=\"cuda\",\n",
    "    n_gpu_layers=-1,\n",
    "    n_ctx=2048,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# default_model = Llama(\n",
    "#     model_path=MODEL_PATH_LLAMA,\n",
    "#     device=\"cuda\",\n",
    "#     n_gpu_layers=-1,\n",
    "#     n_ctx=2048,\n",
    "#     verbose=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_default = \"\"\"\n",
    "[INST] \n",
    "\n",
    "<<SYS>>\n",
    "You are a helpful assistant. \n",
    "Always answer the user's questions in brief and clear sentences. \n",
    "Keep your outputs short while being helpful.\n",
    "<</SYS>>\n",
    "\n",
    "%%%prompt%%%\n",
    "\n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_llm(prompt, enforce_json=True, model=default_model):\n",
    "    if enforce_json is True:\n",
    "        response = model.create_chat_completion(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"\"\"\n",
    "                You are a sentiment analysis model. You are asked to analyze the sentiment of a song based on its lyrics.\n",
    "                \"\"\",\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": lyrics[1]},\n",
    "            ],\n",
    "            response_format={\n",
    "                \"type\": \"json_object\",\n",
    "                \"schema\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"Emotion-Angry_/_Agressive\": {\"type\": \"boolean\"},\n",
    "                        \"Emotion-Arousing_/_Awakening\": {\"type\": \"boolean\"},\n",
    "                        \"Emotion-Bizarre_/_Weird\": {\"type\": \"boolean\"},\n",
    "                        \"Emotion-Calming_/_Soothing\": {\"type\": \"boolean\"},\n",
    "                        \"Emotion-Carefree_/_Lighthearted\": {\"type\": \"boolean\"},\n",
    "                        \"Emotion-Cheerful_/_Festive\": {\"type\": \"boolean\"},\n",
    "                        \"Emotion-Emotional_/_Passionate\": {\"type\": \"boolean\"},\n",
    "                        \"Emotion-Exciting_/_Thrilling\": {\"type\": \"boolean\"},\n",
    "                        \"Emotion-Happy\": {\"type\": \"boolean\"},\n",
    "                        \"Emotion-Laid-back_/_Mellow\": {\"type\": \"boolean\"},\n",
    "                        \"Emotion-Light_/_Playful\": {\"type\": \"boolean\"},\n",
    "                        \"Emotion-Loving_/_Romantic\": {\"type\": \"boolean\"},\n",
    "                        \"Emotion-Pleasant_/_Comfortable\": {\"type\": \"boolean\"},\n",
    "                        \"Emotion-Positive_/_Optimistic\": {\"type\": \"boolean\"},\n",
    "                        \"Emotion-Powerful_/_Strong\": {\"type\": \"boolean\"},\n",
    "                        \"Emotion-Sad\": {\"type\": \"boolean\"},\n",
    "                        \"Emotion-Tender_/_Soft\": {\"type\": \"boolean\"},\n",
    "                        \"Emotion-Touching_/_Loving\": {\"type\": \"boolean\"},\n",
    "                    },\n",
    "                    \"required\": [\n",
    "                        \"Emotion-Angry_/_Agressive\",\n",
    "                        \"Emotion-Arousing_/_Awakening\",\n",
    "                        \"Emotion-Bizarre_/_Weird\",\n",
    "                        \"Emotion-Calming_/_Soothing\",\n",
    "                        \"Emotion-Carefree_/_Lighthearted\",\n",
    "                        \"Emotion-Cheerful_/_Festive\",\n",
    "                        \"Emotion-Emotional_/_Passionate\",\n",
    "                        \"Emotion-Exciting_/_Thrilling\",\n",
    "                        \"Emotion-Happy\",\n",
    "                        \"Emotion-Laid-back_/_Mellow\",\n",
    "                        \"Emotion-Light_/_Playful\",\n",
    "                        \"Emotion-Loving_/_Romantic\",\n",
    "                        \"Emotion-Pleasant_/_Comfortable\",\n",
    "                        \"Emotion-Positive_/_Optimistic\",\n",
    "                        \"Emotion-Powerful_/_Strong\",\n",
    "                        \"Emotion-Sad\",\n",
    "                        \"Emotion-Tender_/_Soft\",\n",
    "                        \"Emotion-Touching_/_Loving\",\n",
    "                    ],\n",
    "                },\n",
    "            },\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        response = model(\n",
    "            prompt_template_default.replace(\"%%%prompt%%%\", prompt),\n",
    "            max_tokens=20000,\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        return response[\"choices\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.23 s, sys: 2.19 s, total: 8.42 s\n",
      "Wall time: 8.66 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current Prime Minister of India is Narendra Modi (as of my knowledge up to 2021).'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "query_llm(\"Who is the Prime Minister of India? Answer in 1 sentence\", False, default_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyric_testing_template = \"\"\"\n",
    "### Lyrics:\n",
    "\n",
    "%%%prompt%%%\n",
    "\n",
    "### Prompt:\n",
    "Fill up the following JSON with 0 or 1 value with respect to the song lyrics. \n",
    "0 means the song does not contain the emotion/genre/usage and 1 means the song contains the emotion/genre/usage.\n",
    "Make sure to fill up every JSON key wiht a value of 0 or 1.\n",
    "If no lyrics are present, respond with an empty JSON object.\n",
    "\n",
    "### JSON\n",
    "{\n",
    "    \"Emotion-Angry_/_Agressive\": \"\"\n",
    "    \"Emotion-Arousing_/_Awakening\": \"\"\n",
    "    \"Emotion-Bizarre_/_Weird\": \"\"\n",
    "    \"Emotion-Calming_/_Soothing\": \"\"\n",
    "    \"Emotion-Carefree_/_Lighthearted\": \"\"\n",
    "    \"Emotion-Cheerful_/_Festive\": \"\"\n",
    "    \"Emotion-Emotional_/_Passionate\": \"\"\n",
    "    \"Emotion-Exciting_/_Thrilling\": \"\"\n",
    "    \"Emotion-Happy\": \"\"\n",
    "    \"Emotion-Laid-back_/_Mellow\": \"\"\n",
    "    \"Emotion-Light_/_Playful\": \"\"\n",
    "    \"Emotion-Loving_/_Romantic\": \"\"\n",
    "    \"Emotion-Pleasant_/_Comfortable\": \"\"\n",
    "    \"Emotion-Positive_/_Optimistic\": \"\"\n",
    "    \"Emotion-Powerful_/_Strong\": \"\"\n",
    "    \"Emotion-Sad\": \"\"\n",
    "    \"Emotion-Tender_/_Soft\": \"\"\n",
    "    \"Emotion-Touching_/_Loving\": \"\"\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_json_output(json_output):\n",
    "    json_output = json.loads(json_output)\n",
    "    json_output = {k: int(v) for k, v in json_output.items()}\n",
    "    json_output = pd.Series(json_output)\n",
    "    return json_output\n",
    "\n",
    "def test_by_index(index):\n",
    "    test_output = query_llm(lyrics[index], True, default_model)\n",
    "    test_output = process_json_output(test_output)\n",
    "    ground_truth = (annotations.iloc[index])\n",
    "\n",
    "    print(ground_truth.compare(test_output))\n",
    "    accuracy = accuracy_score(ground_truth, test_output)\n",
    "    accuracy = round(accuracy, 3)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              self  other\n",
      "Emotion-Arousing_/_Awakening   1.0    0.0\n",
      "Emotion-Exciting_/_Thrilling   1.0    0.0\n",
      "0.889\n",
      "CPU times: user 19.8 s, sys: 4.15 s, total: 24 s\n",
      "Wall time: 24.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(test_by_index(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 self  other\n",
      "Emotion-Angry_/_Agressive         0.0    1.0\n",
      "Emotion-Carefree_/_Lighthearted   1.0    0.0\n",
      "Emotion-Emotional_/_Passionate    0.0    1.0\n",
      "Emotion-Happy                     1.0    0.0\n",
      "Emotion-Light_/_Playful           1.0    0.0\n",
      "Emotion-Positive_/_Optimistic     1.0    0.0\n",
      "0.667\n",
      "CPU times: user 18 s, sys: 1.34 s, total: 19.3 s\n",
      "Wall time: 19.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(test_by_index(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                self  other\n",
      "Emotion-Bizarre_/_Weird          1.0    0.0\n",
      "Emotion-Emotional_/_Passionate   0.0    1.0\n",
      "Emotion-Exciting_/_Thrilling     1.0    0.0\n",
      "Emotion-Powerful_/_Strong        1.0    0.0\n",
      "Emotion-Sad                      1.0    0.0\n",
      "0.722\n",
      "CPU times: user 21.8 s, sys: 1.39 s, total: 23.2 s\n",
      "Wall time: 23.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(test_by_index(69))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 self  other\n",
      "Emotion-Angry_/_Agressive         0.0    1.0\n",
      "Emotion-Carefree_/_Lighthearted   1.0    0.0\n",
      "Emotion-Cheerful_/_Festive        1.0    0.0\n",
      "Emotion-Happy                     1.0    0.0\n",
      "Emotion-Pleasant_/_Comfortable    1.0    0.0\n",
      "Emotion-Powerful_/_Strong         0.0    1.0\n",
      "0.667\n",
      "CPU times: user 16.1 s, sys: 997 ms, total: 17.1 s\n",
      "Wall time: 17.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(test_by_index(43))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 self  other\n",
      "Emotion-Angry_/_Agressive         0.0    1.0\n",
      "Emotion-Carefree_/_Lighthearted   1.0    0.0\n",
      "Emotion-Cheerful_/_Festive        1.0    0.0\n",
      "Emotion-Happy                     1.0    0.0\n",
      "Emotion-Pleasant_/_Comfortable    1.0    0.0\n",
      "0.722\n",
      "CPU times: user 18.6 s, sys: 1.22 s, total: 19.8 s\n",
      "Wall time: 19.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(test_by_index(43))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intial Test Accuracy:\n",
    "| index | llama2-7b | mistral-7b |\n",
    "|-------|--------|---------|\n",
    "|   1   |   83    |    88    |\n",
    "|  500  |   27    |    66    |\n",
    "|   69  |   77    |    72    |\n",
    "|   43  |   72    |    66    |\n",
    "|   99  |   38    |    72    |\n",
    "|---|---|---|\n",
    "| Avg: |   59.4  |    72.8    |\n",
    "\n",
    "Hence, we can see llama2 is better than mistral in most cases, but mistral is very consistent across the board."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
